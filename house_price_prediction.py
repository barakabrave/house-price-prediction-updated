# -*- coding: utf-8 -*-
"""house price prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1phHkiF2f74ZOM5-fHk9Pxgb_Oa-Cp4mr
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler, MinMaxScaler

df=pd.read_csv("/content/housing_price_dataset.csv")
print(df.head(100))
print(df.shape)

from datetime import date
#df.YearBuilt = pd.to_datetime(df.YearBuilt, format='%Y')
df['age_of_the_house']= date.today().year-df['YearBuilt']
le = LabelEncoder()
df.Neighborhood = le.fit_transform(df.Neighborhood)
df.head()

# Define the new order (col2 first, then col1)
 new_order = ['SquareFeet','Bedrooms','Bathrooms','Neighborhood','YearBuilt','age_of_the_house', 'Price']
 df = df[new_order]  # Reorder columns in-place
 df.head()

from scipy import stats  # For IQR outlier detection
# Assuming 'data' is your feature
def detect_outliers_zscore(df, threshold=3.0):
  """
  This function detects outliers in a data array using z-scores.

  Args:
      data (np.array): The data array.
      threshold (float, optional): The z-score threshold for outlier detection (defaults to 3.0).

  Returns:
      tuple: A tuple containing the inlier data (without outliers) and the outlier indices.
  """
  z_scores = np.abs(stats.zscore(df))
  outlier_indices = np.where(z_scores > threshold)[0]
  inlier_data = np.delete(df, outlier_indices)
  return inlier_data, outlier_indices

# Example usage
inlier_data, outlier_indices = detect_outliers_zscore(df)
df.shape

df.drop('YearBuilt',inplace=True,axis=1)
df.columns

sns.pairplot(df)

# Adjust plot layout (optional)
plt.subplots_adjust(top=0.9)  # Adjust top margin for better title placement

# Display the plots
plt.show()

correlation_matrix = df.corr()

# Create a heatmap to visualize the correlations
sns.heatmap(correlation_matrix, annot=True)
plt.title("Correlation Matrix")

# Rotate x-axis labels for better readability
plt.xticks(rotation=45)
plt.show()

plt.bar(df.Neighborhood,df.Price)
plt.xlabel("Neighborhood")
plt.ylabel("Price")
plt.title("Price vs Neigborhood")
plt.show()

scaler = StandardScaler()
df = scaler.fit_transform(df)  # Fit the scaler and transform the data
print(df)



from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error

X = df[:,:5]
y = df[:,5]

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the logistic regression model
Lr_model = LinearRegression()
Lr_model.fit(X_train, y_train)

# Make predictions on test set
predictions = Lr_model.predict(X_test)
mse = mean_squared_error(y_test, predictions)
print(f"Mean Squared Error: {mse:.2f}")
r2 = r2_score(y_test, predictions)*100
print(f"Mean Absolute Error: {mean_absolute_error(y_test, predictions):.2f}")
print(f"R-squared: {r2:.2f}")

from sklearn.linear_model import Lasso, Ridge
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor

lasso_reg = Lasso(alpha=0.1)  # Adjust alpha for regularization strength
lasso_reg.fit(X_train, y_train)

y_pred_lasso = lasso_reg.predict(X_test)
r2_lasso = r2_score(y_test, y_pred_lasso)
print(f"Lasso Regression R-squared: {r2_lasso:.2f}")

ridge_reg = Ridge(alpha=1.0)  # Adjust alpha for regularization strength
ridge_reg.fit(X_train, y_train)

y_pred_ridge = ridge_reg.predict(X_test)
r2_ridge = r2_score(y_test, y_pred_ridge)
print(f"Ridge Regression R-squared: {r2_ridge:.2f}")

random_forest = RandomForestRegressor(n_estimators=100, random_state=42)
random_forest.fit(X_train, y_train)

y_pred_rf = random_forest.predict(X_test)
r2_rf = r2_score(y_test, y_pred_rf)
print(f"Random Forests R-squared: {r2_rf:.2f}")

xgb_model = XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)
xgb_model.fit(X_train, y_train)

y_pred_xgb = xgb_model.predict(X_test)
r2_xgb = r2_score(y_test, y_pred_xgb)
print(f"XGBoost R-squared: {r2_xgb:.2f}")

import pickle
pickle_out = open("house_price_model.pkl", "wb")
pickle.dump(Lr_model, pickle_out)
pickle_out.close()